{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eeac6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, GRU, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70e86342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the 6-line text\n",
    "text = \"\"\"The movie was thrilling and kept me on edge!\n",
    "I found the plot confusing and the pacing too slow.\n",
    "The acting was phenomenal, especially the lead actor.\n",
    "This film is a must-watch for sci-fi fans.\n",
    "The ending was disappointing and felt rushed.\n",
    "Overall, it's a mixed bag but worth a look.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26cd9a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Preprocess the text\n",
    "# Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "total_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63c97a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input sequences\n",
    "input_sequences = []\n",
    "for line in text.split('\\n'):\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03ffbe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f26b67a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create predictors and label\n",
    "X, y = input_sequences[:,:-1], input_sequences[:,-1]\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ba8f90",
   "metadata": {},
   "source": [
    "# define the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dd06691",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN MODEL \n",
    "def create_rnn_model():\n",
    "    model = Sequential([\n",
    "        Embedding(total_words, 10, input_length=max_sequence_len-1),\n",
    "        SimpleRNN(50, return_sequences=False),\n",
    "        Dense(total_words, activation='softmax')\n",
    "    ])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93a6ac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM MODEL \n",
    "def create_lstm_model():\n",
    "    model = Sequential([\n",
    "        Embedding(total_words, 10, input_length=max_sequence_len-1),\n",
    "        LSTM(50, return_sequences=False),\n",
    "        Dense(total_words, activation='softmax')\n",
    "    ])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc479820",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRU MODEL \n",
    "def create_gru_model():\n",
    "    model = Sequential([\n",
    "        Embedding(total_words, 10, input_length=max_sequence_len-1),\n",
    "        GRU(50, return_sequences=False),\n",
    "        Dense(total_words, activation='softmax')\n",
    "    ])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1b125c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANSHIKA\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training RNN model...\n",
      "RNN model training completed.\n",
      "\n",
      "Training LSTM model...\n",
      "LSTM model training completed.\n",
      "\n",
      "Training GRU model...\n",
      "GRU model training completed.\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Train models\n",
    "models = {\n",
    "    'RNN': create_rnn_model(),\n",
    "    'LSTM': create_lstm_model(),\n",
    "    'GRU': create_gru_model()\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name} model...\")\n",
    "    model.fit(X, y, epochs=100, verbose=0)\n",
    "    print(f\"{name} model training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e6ad409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting with RNN model...\n",
      "Input: The movie was, Predicted next word: thrilling\n",
      "\n",
      "Predicting with LSTM model...\n",
      "Input: The movie was, Predicted next word: was\n",
      "\n",
      "Predicting with GRU model...\n",
      "Input: The movie was, Predicted next word: was\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Predict next word\n",
    "seed_text = \"The movie was\"\n",
    "next_words = 1\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nPredicting with {name} model...\")\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = model.predict(token_list, verbose=0)\n",
    "    predicted_word_index = np.argmax(predicted, axis=1)[0]\n",
    "    predicted_word = [word for word, index in tokenizer.word_index.items() if index == predicted_word_index][0]\n",
    "    print(f\"Input: {seed_text}, Predicted next word: {predicted_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b05881b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
